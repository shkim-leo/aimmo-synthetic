{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2632/2632 [00:40<00:00, 64.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일이 생성되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 인스턴스 right / bottom 좌표 -> 높이 / 너비\n",
    "\n",
    "anno_path = \"/data/noah/dataset/ad_human/anno\"\n",
    "out_csv_path = \"/data/noah/dataset/magna_traffic_light/height_info.csv\"\n",
    "samples = []\n",
    "\n",
    "for annotation_name in tqdm(os.listdir(anno_path)):\n",
    "    with open(os.path.join(anno_path, annotation_name), \"r\") as f:\n",
    "        annotation = json.load(f)\n",
    "\n",
    "    height, width = annotation[\"metadata\"][\"height\"], annotation[\"metadata\"][\"width\"]\n",
    "\n",
    "    for ann in annotation[\"annotations\"]:\n",
    "        if (\n",
    "            ann[\"label\"] == \"pedestrian\"\n",
    "            and ann[\"attributes\"][\"occlusion\"] == \"0\"\n",
    "            and ann[\"attributes\"][\"truncation\"] == \"0\"\n",
    "        ):\n",
    "            mask = np.zeros((height, width))\n",
    "\n",
    "            point = np.array(ann[\"points\"], dtype=np.int32)\n",
    "\n",
    "            try:\n",
    "                mask = cv2.fillPoly(mask, [point], color=255).astype(np.uint8)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            spots = np.argwhere(mask == 255)\n",
    "            left = np.min(spots[:, 1])\n",
    "            right = np.max(spots[:, 1])\n",
    "            top = np.min(spots[:, 0])\n",
    "            bottom = np.max(spots[:, 0])\n",
    "\n",
    "            sample = {\"right\": right, \"bottom\": bottom, \"height\": bottom - top + 100, \"width\": right - left + 100}\n",
    "            samples.append(sample)\n",
    "\n",
    "with open(out_csv_path, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"right\", \"bottom\", \"height\", \"width\"])\n",
    "\n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in samples:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"CSV 파일이 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30], Loss: 2932.4531\n",
      "Epoch [10/30], Loss: 3225.9612\n",
      "Epoch [15/30], Loss: 3172.4348\n",
      "Epoch [20/30], Loss: 3201.7507\n",
      "Epoch [25/30], Loss: 3246.0156\n",
      "Epoch [30/30], Loss: 3258.4976\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import torch\n",
    "\n",
    "\n",
    "# 데이터셋 생성\n",
    "# 예제 데이터셋을 생성합니다. 입력은 특정 좌표 (x, y)이고, 출력은 해당 좌표에서의 값입니다.\n",
    "def generate_dataset(num_samples):\n",
    "    # 임의의 좌표 생성\n",
    "    X = np.random.rand(num_samples, 2)\n",
    "    # 임의의 값 생성\n",
    "    y = np.random.rand(num_samples, 1)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# 모델 정의\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 16)  # 입력 크기: 2, 은닉층 크기: 64\n",
    "        self.fc2 = nn.Linear(16, 16)  # 은닉층 크기: 64, 출력 크기: 1\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "def train_model(model, samples, num_epochs, learning_rate, device):\n",
    "    criterion = nn.MSELoss()  # 평균 제곱 오차 손실 함수\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Adam 옵티마이저\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for sample in samples:\n",
    "            right, bottom, height, width = sample\n",
    "\n",
    "            inputs = torch.Tensor([int(right), int(bottom)]).to(device)\n",
    "            targets = torch.Tensor([int(height)]).to(device)\n",
    "\n",
    "            # 순전파 및 손실 계산\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # 역전파 및 가중치 업데이트\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "samples = []\n",
    "out_csv_path = \"/data/noah/dataset/magna_traffic_light/height_info.csv\"\n",
    "# CSV 파일을 읽기 모드로 엽니다.\n",
    "with open(out_csv_path, \"r\", newline=\"\") as csvfile:\n",
    "    # CSV 파일을 읽기 위한 reader 객체를 생성합니다.\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "\n",
    "    # 각 행을 반복하면서 데이터를 처리합니다.\n",
    "    for idx, row in enumerate(csv_reader):\n",
    "        # 각 행의 데이터는 리스트 형태로 반환됩니다.\n",
    "        # 여기에서 데이터를 사용하거나 출력합니다.\n",
    "        if not idx:\n",
    "            continue\n",
    "\n",
    "        samples.append(row)\n",
    "\n",
    "device = \"cuda:2\"\n",
    "torch.cuda.set_device(device)\n",
    "\n",
    "# 모델 초기화\n",
    "model = MLP().to(device)\n",
    "\n",
    "# 모델 학습\n",
    "num_epochs = 30\n",
    "learning_rate = 0.01\n",
    "train_model(model, samples, num_epochs, learning_rate, device)\n",
    "\n",
    "ckpt_path = \"/data/noah/dataset/magna_traffic_light/height_model.ckpt\"\n",
    "torch.save(model.state_dict(), ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(ckpt_path))\n",
    "\n",
    "# 테스트 데이터 입력\n",
    "# 32, 15\n",
    "input_coordinate = [1312, 566]\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "input_tensor = torch.Tensor(input_coordinate).to(device)\n",
    "predicted_value = model(input_tensor)\n",
    "print(predicted_value.detach().cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
