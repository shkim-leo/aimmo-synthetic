{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Mask & Image 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "\n",
    "def crop_from_mask(image, mask):\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # If no contours found, return original image\n",
    "    if not contours:\n",
    "        return image\n",
    "\n",
    "    # Find the bounding box of the largest contour\n",
    "    x, y, w, h = cv2.boundingRect(contours[0])\n",
    "\n",
    "    # Crop the image using the bounding box\n",
    "    cropped_image = image[y : y + h, x : x + w]\n",
    "    cropped_mask = mask[y : y + h, x : x + w]\n",
    "\n",
    "    return cropped_image, cropped_mask\n",
    "\n",
    "\n",
    "annotation_path = \"/data/noah/dataset/ad_human/anno\"\n",
    "out_mask_path = \"/data/noah/inference/ad_premask/masks\"\n",
    "out_image_path = \"/data/noah/inference/ad_premask/images\"\n",
    "out_csv_path = \"/data/noah/inference/ad_premask/instance_infos.csv\"\n",
    "cnt = 0\n",
    "target_class = \"pedestrian\"\n",
    "\n",
    "instance_infos = []\n",
    "\n",
    "for anno_name in tqdm(os.listdir(annotation_path)):\n",
    "    anno_path = os.path.join(annotation_path, anno_name)\n",
    "\n",
    "    with open(anno_path, \"r\") as f:\n",
    "        annotation = json.load(f)\n",
    "\n",
    "    image_path = os.path.join(annotation[\"parent_path\"], annotation[\"filename\"])\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    # generate crop mask and image\n",
    "    target_idxs = []\n",
    "    for idx, anno in enumerate(annotation[\"annotations\"]):\n",
    "        if (\n",
    "            anno[\"label\"] == target_class\n",
    "            and anno[\"attributes\"][\"occlusion\"] == \"0\"\n",
    "            and anno[\"attributes\"][\"truncation\"] == \"0\"\n",
    "        ):\n",
    "            target_idxs.append(idx)\n",
    "\n",
    "    for target_idx in target_idxs:\n",
    "        mask = np.zeros((image.height, image.width))\n",
    "        point = np.array(annotation[\"annotations\"][target_idx][\"points\"], dtype=np.int32)\n",
    "        try:\n",
    "            mask = cv2.fillPoly(mask, [point], color=255)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        cnt += 1\n",
    "        crop_image, crop_mask = crop_from_mask(np.array(image), mask.astype(\"uint8\"))\n",
    "        # display(Image.fromarray(crop_image))\n",
    "        # display(Image.fromarray(crop_mask))\n",
    "        crop_image = Image.fromarray(crop_image)\n",
    "        crop_mask = Image.fromarray(crop_mask)\n",
    "\n",
    "        crop_image.save(os.path.join(out_image_path, \"{}.png\".format(cnt)))\n",
    "        crop_mask.save(os.path.join(out_mask_path, \"{}.png\".format(cnt)))\n",
    "        info = {\n",
    "            \"image_path\": image_path,\n",
    "            \"image_height\": crop_mask.height,\n",
    "        }\n",
    "        instance_infos.append(info)\n",
    "\n",
    "sorted_infos = sorted(instance_infos, key=lambda x: x[\"image_height\"])\n",
    "\n",
    "with open(out_csv_path, mode=\"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"image_path\", \"image_height\"])\n",
    "    writer.writeheader()\n",
    "    for row in sorted_infos:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ControlNet Inpainting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from diffusers import StableDiffusionControlNetInpaintPipeline, ControlNetModel, DDIMScheduler\n",
    "from controlnet_aux.processor import MidasDetector\n",
    "import sys\n",
    "\n",
    "sys.path.insert(os.getcwd(), \"../harmonization\")\n",
    "from harmonization import Harmonization\n",
    "from gtgen.bpr import GtGenBPRInference\n",
    "\n",
    "\n",
    "def make_inputs(image, annotation, target_indexs, harmonizer, midas, ann_idx):\n",
    "    height, width = annotation[\"metadata\"][\"height\"], annotation[\"metadata\"][\"width\"]\n",
    "    mask = np.zeros((height, width))\n",
    "    spot = None\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    # Coefficients of the polynomial\n",
    "    coefficients = [7.62995538e-14, -2.57068472e-10, 3.25925629e-07, -1.90207658e-04, 5.09169229e-02, -5.35772215e+00, 2.35348832e+02]\n",
    "    # Create a polynomial object using poly1d\n",
    "    height_poly = np.poly1d(coefficients)\n",
    "\n",
    "    while True:\n",
    "        target_index = random.choice(target_indexs)\n",
    "        rb_spot = random_coordinate(annotation[\"annotations\"], target_index, height, width)  # height, width 순\n",
    "\n",
    "        if rb_spot is None:\n",
    "            print(\"{} can not generate right bottom spot\".format(annotation[\"filename\"]))\n",
    "            return None\n",
    "\n",
    "        # rb_spot x값을 기준으로 height 선정 및 target_height 산출\n",
    "        # target_height = random.randint(500, 500)\n",
    "        target_height = int(height_poly(rb_spot[0]))\n",
    "        mask_name = random.choice(mask_lists)\n",
    "\n",
    "        image_pth = os.path.join(image_path, mask_name)\n",
    "        mask_pth = os.path.join(mask_path, mask_name)\n",
    "\n",
    "        paste_image = Image.open(image_pth)\n",
    "        paste_mask = Image.open(mask_pth)\n",
    "\n",
    "        ratio = float(target_height) / paste_mask.height\n",
    "        paste_mask = paste_mask.resize((int(paste_mask.width * ratio), int(paste_mask.height * ratio)))\n",
    "        paste_image = paste_image.resize((int(paste_image.width * ratio), int(paste_image.height * ratio)))\n",
    "\n",
    "        paste_mask = np.array(paste_mask).astype(\"uint8\")\n",
    "        paste_image = np.array(paste_image).astype(\"uint8\")\n",
    "\n",
    "        if np.sum(paste_mask) == 0:\n",
    "            continue\n",
    "\n",
    "        paste_mask = cv2.morphologyEx(paste_mask, cv2.MORPH_OPEN, k, iterations=3)\n",
    "        # paste_mask = cv2.dilate(paste_mask, k, iterations=2)\n",
    "        paste_mask = np.where(paste_mask > 127, 255, 0).astype(\"uint8\")\n",
    "        sum_mask = add_mask(mask, paste_mask, rb_spot[1], rb_spot[0])\n",
    "\n",
    "        if sum_mask is None:\n",
    "            continue\n",
    "\n",
    "        spot = np.argwhere(sum_mask == 255)\n",
    "        sum_image = add_image(image, paste_image, paste_mask, rb_spot[1], rb_spot[0])\n",
    "        break\n",
    "\n",
    "    sum_image = harmonizer.harmonize(sum_image, sum_mask)\n",
    "    sum_image = Image.fromarray(sum_image.astype(\"uint8\")).convert(\"RGB\")\n",
    "    sum_mask = Image.fromarray(sum_mask.astype(\"uint8\")).convert(\"L\")\n",
    "    con_image = midas(sum_image, image_resolution=height)\n",
    "\n",
    "    output = {\"image\": sum_image, \"mask\": sum_mask, \"con_image\": con_image, \"spot\": spot}\n",
    "    return output\n",
    "\n",
    "def make_grid(images, rows, cols):\n",
    "    w, h = images[0].size\n",
    "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
    "    for i, image in enumerate(images):\n",
    "        grid.paste(image, box=(i % cols * w, i // cols * h))\n",
    "    return grid\n",
    "\n",
    "\n",
    "def find_outer_contour_coordinates(mask):\n",
    "    # OpenCV의 findContours 함수를 사용하여 이진 이미지의 외곽선을 찾습니다.\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # 외곽선을 이루는 점들의 좌표를 반환합니다.\n",
    "    outer_contour_coords = [[], []]\n",
    "    for contour in contours:\n",
    "        for point in contour:\n",
    "            x, y = point[0]\n",
    "            outer_contour_coords[0].append(y)\n",
    "            outer_contour_coords[1].append(x)\n",
    "\n",
    "    return outer_contour_coords\n",
    "\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    return np.sqrt((point2[0] - point1[0]) ** 2 + (point2[1] - point1[1]) ** 2)\n",
    "\n",
    "\n",
    "def random_coordinate(annotation, target_index, height, width):\n",
    "    mask = np.zeros((height, width))\n",
    "    mask, state = polygon_to_mask(mask, annotation[target_index][\"points\"], color=255)\n",
    "\n",
    "    if not state:\n",
    "        return None\n",
    "\n",
    "    for idx, ann in enumerate(annotation):\n",
    "        if idx == target_index:\n",
    "            continue\n",
    "\n",
    "        mask, state = polygon_to_mask(mask, ann[\"points\"], color=0)\n",
    "\n",
    "    target_spots = np.argwhere(mask == 255).tolist()\n",
    "\n",
    "    if len(target_spots) == 0:\n",
    "        return None\n",
    "\n",
    "    coordinates = find_outer_contour_coordinates(mask)\n",
    "    threshold = 500\n",
    "\n",
    "    # 랜덤으로 좌표 선택\n",
    "    while True:\n",
    "        target_spot = random.choice(target_spots)  # height,width 순\n",
    "        distances = [\n",
    "            euclidean_distance((coord[0], coord[1]), target_spot) for coord in zip(coordinates[0], coordinates[1])\n",
    "        ]\n",
    "        min_distance = int(min(distances))\n",
    "\n",
    "        if min_distance >= threshold:\n",
    "            return target_spot\n",
    "        else:\n",
    "            threshold = threshold // 2\n",
    "\n",
    "\n",
    "def add_mask(mask, new_mask, right, bottom):\n",
    "    mask_cp = mask.copy()\n",
    "\n",
    "    # 새로운 마스크를 더할 위치 계산\n",
    "    left = right - new_mask.shape[1]\n",
    "    top = bottom - new_mask.shape[0]\n",
    "\n",
    "    # 마스크 영역에 새로운 마스크 더하기\n",
    "    if left < 0 or top < 0:\n",
    "        return None\n",
    "\n",
    "    mask_cp[top:bottom, left:right] += new_mask\n",
    "\n",
    "    return mask_cp\n",
    "\n",
    "\n",
    "def add_image(image, new_image, mask, right, bottom):\n",
    "    image_cp = image.copy()\n",
    "\n",
    "    # 새로운 마스크를 더할 위치 계산\n",
    "    left = right - new_image.shape[1]\n",
    "    top = bottom - new_image.shape[0]\n",
    "\n",
    "    # 마스크 영역에 새로운 마스크 더하기\n",
    "    if left < 0 or top < 0:\n",
    "        return None\n",
    "\n",
    "    for h in range(top, bottom):\n",
    "        for w in range(left, right):\n",
    "            if mask[h - top, w - left]:\n",
    "                image_cp[h, w, :] = new_image[h - top, w - left, :]\n",
    "\n",
    "    return image_cp\n",
    "\n",
    "\n",
    "def make_dirs(paths):\n",
    "    for path in paths:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def make_result(image, mask):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    image_with_mask_contours = np.copy(image)\n",
    "    cv2.drawContours(image_with_mask_contours, contours, -1, (0, 0, 255), 2)\n",
    "    return image_with_mask_contours\n",
    "\n",
    "\n",
    "def mask_refinement(image, ann, bpr_inference):\n",
    "    seg_result = bpr_inference.inference(\n",
    "        img=image,\n",
    "        seg=ann,\n",
    "        img_scale=(256, 256),\n",
    "        img_ratios=[1.0, 1.5, 2.0],\n",
    "        nms_iou_threshold=0.5,\n",
    "        point_density=0.25,\n",
    "        patch_size=[32, 64, 96],\n",
    "        padding=0,\n",
    "    )\n",
    "\n",
    "    height, width = image.shape[0], image.shape[1]\n",
    "    result_map = np.zeros((height, width))\n",
    "\n",
    "    for sr in seg_result[\"annotations\"]:\n",
    "        result_map, state = polygon_to_mask(result_map, sr[\"points\"], 255)\n",
    "\n",
    "    return result_map.astype(\"uint8\")\n",
    "\n",
    "\n",
    "def mask_to_polygon(mask):\n",
    "    # 윤곽선 찾기\n",
    "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # 윤곽선을 다각형으로 변환\n",
    "    polygons = []\n",
    "    for contour in contours:\n",
    "        contour = contour.squeeze(axis=1)  # 차원 축소\n",
    "        polygon = contour[:, [0, 1]].tolist()  # (y, x) 순서로 변환하여 리스트로 저장\n",
    "        polygons.append(polygon)\n",
    "\n",
    "    return polygons\n",
    "\n",
    "\n",
    "def polygon_to_mask(mask, polygons, color=255):\n",
    "    polygons = np.array(polygons, dtype=np.int32)\n",
    "    state = False\n",
    "\n",
    "    try:\n",
    "        mask = cv2.fillPoly(mask.astype(\"uint8\"), [polygons], color)\n",
    "        state = True\n",
    "    except:\n",
    "        print(\"mask passed!\")\n",
    "\n",
    "    return mask, state\n",
    "\n",
    "\n",
    "def modify_annotation(annotations, polygons, height, width):\n",
    "    # draw generated mask\n",
    "    generated_mask = np.zeros((height, width))\n",
    "    generated_annotations = []\n",
    "    original_annotations = []\n",
    "\n",
    "    for polygon in polygons:\n",
    "        generated_mask, state = polygon_to_mask(generated_mask, polygon, 255)\n",
    "\n",
    "        if state:\n",
    "            ann = {\n",
    "                \"id\": \"\",\n",
    "                \"type\": \"poly_seg\",\n",
    "                \"attributes\": {},\n",
    "                \"points\": polygon,\n",
    "                \"label\": \"person\",\n",
    "            }\n",
    "            generated_annotations.append(ann)\n",
    "\n",
    "    for annotation in annotations:\n",
    "        # draw original mask\n",
    "        original_mask = np.zeros((height, width))\n",
    "        original_mask, state = polygon_to_mask(original_mask, annotation[\"points\"], 255)\n",
    "\n",
    "        if not state:\n",
    "            continue\n",
    "\n",
    "        # modify original mask\n",
    "        original_mask = np.where((original_mask == 255) & (generated_mask == 255), 0, original_mask)\n",
    "        original_polygons = mask_to_polygon(original_mask)\n",
    "\n",
    "        for polygon in original_polygons:\n",
    "            ann = copy.deepcopy(annotation)\n",
    "            ann[\"points\"] = polygon\n",
    "            original_annotations.append(ann)\n",
    "\n",
    "    original_annotations.extend(generated_annotations)\n",
    "    return original_annotations\n",
    "\n",
    "\n",
    "device = \"cuda:2\"\n",
    "\n",
    "# 사전 정의된 Crop 이미지와 마스크\n",
    "mask_path = \"/data/noah/inference/magna_human_premask/masks\"\n",
    "image_path = \"/data/noah/inference/magna_human_premask/images\"\n",
    "mask_lists = os.listdir(mask_path)\n",
    "\n",
    "# 생성할 Annotation 정보\n",
    "base_image_path = \"/data/noah/dataset/magna_traffic_light/pre_images\"\n",
    "target_annotation_path = \"/data/noah/dataset/magna_traffic_light/pre_anno\"\n",
    "target_class_name = \"road\"\n",
    "target_height = None\n",
    "\n",
    "save_base_path = \"/data/noah/inference/magna_controlnet_inpainting_f\"\n",
    "save_result_path = os.path.join(save_base_path, \"results\")\n",
    "save_draw_path = os.path.join(save_base_path, \"draw_results\")\n",
    "save_refined_draw_path = os.path.join(save_base_path, \"draw_results_refined\")\n",
    "save_annotation_draw_path = os.path.join(save_base_path, \"annotation_draw\")\n",
    "save_modified_annotation_draw_path = os.path.join(save_base_path, \"modified_annotation_draw\")\n",
    "save_mask_path = os.path.join(save_base_path, \"masks\")\n",
    "make_dirs(\n",
    "    [\n",
    "        save_base_path,\n",
    "        save_result_path,\n",
    "        save_draw_path,\n",
    "        save_refined_draw_path,\n",
    "        save_modified_annotation_draw_path,\n",
    "        save_annotation_draw_path,\n",
    "        save_mask_path,\n",
    "    ]\n",
    ")\n",
    "\n",
    "bpr_inference = GtGenBPRInference(devices=[2], batch_size=48)\n",
    "bpr_model = bpr_inference.load_model(\"/data/noah/ckpt/finetuning/bpr.pth\", img_scale=(256, 256))\n",
    "assert bpr_model is not None, \"model not loaded\"\n",
    "\n",
    "midas = MidasDetector.from_pretrained(\"lllyasviel/Annotators\").to(device)\n",
    "harmonizer = Harmonization(\"/data/noah/ckpt/pretrain_ckpt/duconet/duconet1024.pth\", device=device)\n",
    "\n",
    "model_id = \"/data/noah/ckpt/pretrain_ckpt/StableDiffusion/rv_inpaint_5.1\"\n",
    "controlnet_id = \"/data/noah/ckpt/finetuning/controlnet_inpaint_coco/checkpoint-180000/controlnet\"\n",
    "lora_id = \"/data/noah/ckpt/pretrain_ckpt/StableDiffusion/lora_detail\"\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(controlnet_id, torch_dtype=torch.float16)\n",
    "pipe = StableDiffusionControlNetInpaintPipeline.from_pretrained(\n",
    "    model_id, controlnet=controlnet, torch_dtype=torch.float16\n",
    ").to(device)\n",
    "pipe.load_lora_weights(lora_id, weight_name=\"add_detail.safetensors\")\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.enable_freeu(s1=1.2, s2=0.5, b1=1.2, b2=1.4)\n",
    "# generator = torch.Generator(device=device).manual_seed(42)\n",
    "\n",
    "prompt = \"a person is on the road, RAW photo, subject, 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3, <lora:add-detail:1>\"\n",
    "negative_prompt = \"(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime), blurry, text, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, UnrealisticDream\"\n",
    "num_inference_steps = 25\n",
    "guidance_scale = 7.5\n",
    "strength = 1.0\n",
    "sag_scale = 0.75\n",
    "controlnet_conditioning_scale = 0.75\n",
    "\n",
    "# write parameter\n",
    "with open(os.path.join(save_base_path, \"param.txt\"), \"w\") as f:\n",
    "    f.write(\"Description : 추론 결과\\n\")\n",
    "    f.write(\"base model : {}\\n\".format(model_id))\n",
    "    f.write(\"controlnet model : {}\\n\".format(controlnet_id))\n",
    "    f.write(\"lora model : {}\\n\".format(lora_id))\n",
    "    f.write(\"scheduler : {}\\n\".format(pipe.scheduler))\n",
    "\n",
    "    f.write(\"prompt : {}\\n\".format(prompt))\n",
    "    f.write(\"negative prompt : {}\\n\".format(negative_prompt))\n",
    "    f.write(\"num_inference_steps : {}\\n\".format(num_inference_steps))\n",
    "    f.write(\"guidance_scale : {}\\n\".format(guidance_scale))\n",
    "    f.write(\"strength : {}\\n\".format(strength))\n",
    "    f.write(\"controlnet_conditioning_scale : {}\\n\".format(controlnet_conditioning_scale))\n",
    "    f.write(\"sag_scale : {}\\n\".format(sag_scale))\n",
    "\n",
    "for ann_idx, ann_name in tqdm(enumerate(os.listdir(target_annotation_path)[:10])):\n",
    "    annotation_path = os.path.join(target_annotation_path, ann_name)\n",
    "\n",
    "    with open(annotation_path, \"r\") as f:\n",
    "        annotation = json.load(f)\n",
    "\n",
    "    target_indexs = []\n",
    "\n",
    "    for idx, ann in enumerate(annotation[\"annotations\"]):\n",
    "        if ann[\"label\"] == target_class_name:\n",
    "            target_indexs.append(idx)\n",
    "\n",
    "    if not len(target_indexs):\n",
    "        continue\n",
    "\n",
    "    height, width = annotation[\"metadata\"][\"height\"], annotation[\"metadata\"][\"width\"]\n",
    "    image = Image.open(os.path.join(base_image_path, annotation[\"parent_path\"][1:], annotation[\"filename\"]))\n",
    "    image = np.array(image).astype(\"uint8\")\n",
    "\n",
    "    sum_mask_image = np.zeros((height, width))\n",
    "    sum_result_image = np.copy(image)\n",
    "    sum_draw_image = None\n",
    "\n",
    "    generate_cnt = random.randint(1, 4)\n",
    "    inputs = None\n",
    "    generated_spots = []\n",
    "\n",
    "    for iter_cnt in range(generate_cnt):\n",
    "        inputs = make_inputs(image, annotation, mask_lists, target_indexs, harmonizer, midas)\n",
    "\n",
    "        if inputs is None:\n",
    "            break\n",
    "\n",
    "        if len(generated_spots) and np.any(np.all(np.isin(np.array(generated_spots), inputs[\"spot\"]), axis=1)):\n",
    "            continue\n",
    "        else:\n",
    "            generated_spots.extend(inputs[\"spot\"].tolist())\n",
    "\n",
    "        result_image = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            image=inputs[\"image\"],\n",
    "            control_image=inputs[\"con_image\"],\n",
    "            mask_image=inputs[\"mask\"],\n",
    "            height=inputs[\"image\"].height,\n",
    "            width=inputs[\"image\"].width,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            strength=strength,\n",
    "            sag_scale=sag_scale,\n",
    "            controlnet_conditioning_scale=controlnet_conditioning_scale,\n",
    "            padding_mask_crop=8,\n",
    "        ).images[0]\n",
    "\n",
    "        result_image = harmonizer.harmonize(np.array(result_image), np.array(inputs[\"mask\"]))\n",
    "        result_image = result_image.astype(\"uint8\")\n",
    "\n",
    "        for spot in inputs[\"spot\"]:\n",
    "            sum_result_image[spot[0], spot[1], :] = result_image[spot[0], spot[1], :]\n",
    "\n",
    "        sum_mask_image = sum_mask_image + np.array(inputs[\"mask\"])\n",
    "\n",
    "    if inputs is not None:\n",
    "        # mask refinement\n",
    "        polygons = mask_to_polygon(sum_mask_image)\n",
    "        generated_annotation = copy.deepcopy(annotation)\n",
    "        anns = []\n",
    "\n",
    "        for polygon in polygons:\n",
    "            an = {\n",
    "                \"id\": \"\",\n",
    "                \"type\": \"poly_seg\",\n",
    "                \"attributes\": {},\n",
    "                \"points\": polygon,\n",
    "                \"label\": \"person\",\n",
    "            }\n",
    "            anns.append(an)\n",
    "\n",
    "        generated_annotation[\"annotations\"] = anns\n",
    "        refined_mask = mask_refinement(sum_result_image, generated_annotation, bpr_inference)\n",
    "        polygons = mask_to_polygon(refined_mask)\n",
    "\n",
    "        # draw result image with mask\n",
    "        sum_draw_image = make_result(np.copy(sum_result_image), sum_mask_image.astype(\"uint8\"))\n",
    "        sum_draw_refined_image = make_result(np.copy(sum_result_image), refined_mask)\n",
    "\n",
    "        # annotation 수정 작업 #\n",
    "        modified_annotation = modify_annotation(\n",
    "            annotation[\"annotations\"],\n",
    "            polygons,\n",
    "            height,\n",
    "            width,\n",
    "        )\n",
    "\n",
    "        # draw annotation\n",
    "        original_mask = np.zeros((height, width, 3))\n",
    "        modified_mask = np.zeros((height, width, 3))\n",
    "\n",
    "        for ann in annotation[\"annotations\"]:\n",
    "            original_mask, state = polygon_to_mask(\n",
    "                original_mask,\n",
    "                ann[\"points\"],\n",
    "                color=(\n",
    "                    random.randint(0, 255),\n",
    "                    random.randint(0, 255),\n",
    "                    random.randint(0, 255),\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        for m_ann in modified_annotation:\n",
    "            modified_mask, state = polygon_to_mask(\n",
    "                modified_mask,\n",
    "                m_ann[\"points\"],\n",
    "                color=(\n",
    "                    random.randint(0, 255),\n",
    "                    random.randint(0, 255),\n",
    "                    random.randint(0, 255),\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        Image.fromarray(sum_result_image.astype(\"uint8\")).convert(\"RGB\").save(\n",
    "            os.path.join(save_result_path, annotation[\"filename\"])\n",
    "        )\n",
    "        Image.fromarray(sum_draw_image.astype(\"uint8\")).convert(\"RGB\").save(\n",
    "            os.path.join(save_draw_path, annotation[\"filename\"])\n",
    "        )\n",
    "        Image.fromarray(sum_draw_refined_image.astype(\"uint8\")).convert(\"RGB\").save(\n",
    "            os.path.join(save_refined_draw_path, annotation[\"filename\"])\n",
    "        )\n",
    "        Image.fromarray(original_mask.astype(\"uint8\")).convert(\"RGB\").save(\n",
    "            os.path.join(save_annotation_draw_path, annotation[\"filename\"])\n",
    "        )\n",
    "        Image.fromarray(modified_mask.astype(\"uint8\")).convert(\"RGB\").save(\n",
    "            os.path.join(save_modified_annotation_draw_path, annotation[\"filename\"])\n",
    "        )\n",
    "        Image.fromarray(sum_mask_image.astype(\"uint8\")).convert(\"L\").save(\n",
    "            os.path.join(save_mask_path, annotation[\"filename\"])\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ControlNet + Inpainting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from diffusers import StableDiffusionDisControlNetInpaintPipeline, ControlNetModel, DDIMScheduler\n",
    "from controlnet_aux.processor import MidasDetector\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../harmonization\")\n",
    "from harmonization import Harmonization\n",
    "\n",
    "\n",
    "def make_grid(images, rows, cols):\n",
    "    w, h = images[0].size\n",
    "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
    "    for i, image in enumerate(images):\n",
    "        grid.paste(image, box=(i % cols * w, i // cols * h))\n",
    "    return grid\n",
    "\n",
    "\n",
    "def find_outer_contour_coordinates(mask):\n",
    "    # OpenCV의 findContours 함수를 사용하여 이진 이미지의 외곽선을 찾습니다.\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # 외곽선을 이루는 점들의 좌표를 반환합니다.\n",
    "    outer_contour_coords = [[], []]\n",
    "    for contour in contours:\n",
    "        for point in contour:\n",
    "            y, x = point[0]\n",
    "            outer_contour_coords[0].append(y)\n",
    "            outer_contour_coords[1].append(x)\n",
    "\n",
    "    return outer_contour_coords\n",
    "\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    return np.sqrt((point2[0] - point1[0]) ** 2 + (point2[1] - point1[1]) ** 2)\n",
    "\n",
    "\n",
    "def random_coordinate(mask):\n",
    "    # 값이 255인 좌표 찾기\n",
    "    coordinates = find_outer_contour_coordinates(mask)\n",
    "\n",
    "    center_x = int((np.max(coordinates[1]) - np.min(coordinates[1])) / 2) + np.min(coordinates[1])\n",
    "    center_y = int((np.max(coordinates[0]) - np.min(coordinates[0])) / 2) + np.min(coordinates[0])\n",
    "    center = (center_y, center_x)\n",
    "\n",
    "    distances = [euclidean_distance((coord[0], coord[1]), center) for coord in zip(coordinates[0], coordinates[1])]\n",
    "    radius = int(min(distances))\n",
    "\n",
    "    # 랜덤으로 좌표 선택\n",
    "    while True:\n",
    "        random_x = random.randint(center_x - radius, center_x + radius)\n",
    "        random_y = random.randint(center_y - radius, center_y + radius)\n",
    "\n",
    "        try:\n",
    "            if mask[random_y, random_x] != 0:\n",
    "                return (random_y, random_x)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "def add_mask(mask, new_mask, right, bottom):\n",
    "    # 새로운 마스크를 더할 위치 계산\n",
    "    left = right - new_mask.shape[1]\n",
    "    top = bottom - new_mask.shape[0]\n",
    "\n",
    "    # 마스크 영역에 새로운 마스크 더하기\n",
    "    if left < 0 or top < 0:\n",
    "        return None\n",
    "\n",
    "    mask[top:bottom, left:right] += new_mask\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def add_image(image, new_image, mask, right, bottom):\n",
    "    # 새로운 마스크를 더할 위치 계산\n",
    "    left = right - new_image.shape[1]\n",
    "    top = bottom - new_image.shape[0]\n",
    "\n",
    "    # 마스크 영역에 새로운 마스크 더하기\n",
    "    if left < 0 or top < 0:\n",
    "        return None\n",
    "\n",
    "    for h in range(top, bottom):\n",
    "        for w in range(left, right):\n",
    "            if mask[h - top, w - left]:\n",
    "                image[h, w, :] = new_image[h - top, w - left, :]\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def make_dirs(paths):\n",
    "    for path in paths:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def make_result(image, mask):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    image_with_mask_contours = np.copy(image)\n",
    "    cv2.drawContours(image_with_mask_contours, contours, -1, (0, 255, 0), 2)\n",
    "    return image_with_mask_contours\n",
    "\n",
    "\n",
    "device = \"cuda:1\"\n",
    "torch.cuda.set_device(device)\n",
    "\n",
    "# 사전 정의된 Crop 이미지와 마스크\n",
    "mask_path = \"/data/noah/inference/ad_premask/masks\"\n",
    "image_path = \"/data/noah/inference/ad_premask/images\"\n",
    "mask_lists = os.listdir(mask_path)\n",
    "\n",
    "# 생성할 Annotation 정보\n",
    "base_image_path = \"/data/noah/dataset/magna_traffic_light/pre_images\"\n",
    "target_annotation_path = \"/data/noah/dataset/magna_traffic_light/pre_anno\"\n",
    "target_class_name = \"road\"\n",
    "target_height = None\n",
    "\n",
    "save_base_path = \"/data/noah/inference/magna_controlnet\"\n",
    "save_origin_image_path = os.path.join(save_base_path, \"images\")\n",
    "save_mask_path = os.path.join(save_base_path, \"masks\")\n",
    "save_paste_image_path = os.path.join(save_base_path, \"paste_images\")\n",
    "save_pre_harmo_con_path = os.path.join(save_base_path, \"pre_harmo_con_images\")\n",
    "save_after_harmo_image_path = os.path.join(save_base_path, \"after_harmo_images\")\n",
    "save_after_harmo_con_path = os.path.join(save_base_path, \"after_harmo_con_images\")\n",
    "save_result_path = os.path.join(save_base_path, \"result_images\")\n",
    "save_result_harmo_path = os.path.join(save_base_path, \"result_harmo_images\")\n",
    "save_total_path = os.path.join(save_base_path, \"total_results\")\n",
    "\n",
    "make_dirs(\n",
    "    [\n",
    "        save_base_path,\n",
    "        save_origin_image_path,\n",
    "        save_mask_path,\n",
    "        save_paste_image_path,\n",
    "        save_pre_harmo_con_path,\n",
    "        save_after_harmo_image_path,\n",
    "        save_after_harmo_con_path,\n",
    "        save_result_path,\n",
    "        save_result_harmo_path,\n",
    "        save_total_path,\n",
    "    ]\n",
    ")\n",
    "\n",
    "midas = MidasDetector.from_pretrained(\"lllyasviel/Annotators\").to(\"cuda:1\")\n",
    "harmonizer = Harmonization(\"/data/noah/ckpt/pretrain_ckpt/duconet/duconet1024.pth\", device=\"cuda:1\")\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    \"/data/noah/ckpt/finetuning/controlnet_coco/checkpoint-40000/controlnet\", torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# /data/noah/ckpt/pretrain_ckpt/StableDiffusion/inpaint\n",
    "# /data/noah/ckpt/pretrain_ckpt/StableDiffusion/rv_inpaint\n",
    "pipe = StableDiffusionDisControlNetInpaintPipeline.from_pretrained(\n",
    "    \"/data/noah/ckpt/pretrain_ckpt/StableDiffusion/rv_inpaint\", controlnet=controlnet, torch_dtype=torch.float16\n",
    ").to(device)\n",
    "\n",
    "\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "generator = torch.Generator(device=device).manual_seed(42)\n",
    "\n",
    "prompt = \"{}, best quality, extremely detailed, clearness, naturalness, film grain, crystal clear, photo with color, actuality\"\n",
    "negative_prompt = \"cartoon, anime, painting, disfigured, immature, blur, picture, 3D, render, semi-realistic, drawing, poorly drawn, bad anatomy, wrong anatomy, gray scale, worst quality, low quality, sketch, text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck\"\n",
    "\n",
    "\n",
    "for ann_idx, ann_name in tqdm(enumerate(os.listdir(target_annotation_path)[:40])):\n",
    "    annotation_path = os.path.join(target_annotation_path, ann_name)\n",
    "\n",
    "    with open(annotation_path, \"r\") as f:\n",
    "        annotation = json.load(f)\n",
    "\n",
    "    target_indexs = []\n",
    "\n",
    "    for idx, ann in enumerate(annotation[\"annotations\"]):\n",
    "        if ann[\"label\"] == target_class_name:\n",
    "            target_indexs.append(idx)\n",
    "            break\n",
    "\n",
    "    if not len(target_indexs):\n",
    "        continue\n",
    "\n",
    "    iter_cnt = 0\n",
    "\n",
    "    while True:\n",
    "        # polygon to mask\n",
    "        if iter_cnt > 50:\n",
    "            break\n",
    "        else:\n",
    "            iter_cnt += 1\n",
    "        target_index = random.choice(target_indexs)\n",
    "        mask = np.zeros((annotation[\"metadata\"][\"height\"], annotation[\"metadata\"][\"width\"]))\n",
    "        image = Image.open(os.path.join(base_image_path, annotation[\"parent_path\"][1:], annotation[\"filename\"]))\n",
    "        target_mask = np.copy(mask)\n",
    "\n",
    "        point = np.array(annotation[\"annotations\"][target_index][\"points\"], dtype=np.int32)\n",
    "        try:\n",
    "            target_mask = cv2.fillPoly(target_mask, [point], color=255).astype(np.uint8)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        rb_spot = random_coordinate(target_mask)  # height, width 순\n",
    "\n",
    "        # rb_spot x값을 기준으로 height 선정 및 target_height 산출\n",
    "        target_height = random.randint(350, 600)\n",
    "\n",
    "        # 사전에 저장한 mask로부터 랜덤으로 하나 선택 후 target_height로 리사이징\n",
    "        # mask_name = random.choice(mask_lists)\n",
    "        mask_name = mask_lists[ann_idx]\n",
    "\n",
    "        image_pth = os.path.join(image_path, mask_name)\n",
    "        mask_pth = os.path.join(mask_path, mask_name)\n",
    "\n",
    "        paste_image = Image.open(image_pth)\n",
    "        paste_mask = Image.open(mask_pth)\n",
    "\n",
    "        ratio = float(target_height) / paste_mask.height\n",
    "        paste_mask = paste_mask.resize((int(paste_mask.width * ratio), int(paste_mask.height * ratio)))\n",
    "        paste_image = paste_image.resize((int(paste_image.width * ratio), int(paste_image.height * ratio)))\n",
    "\n",
    "        paste_mask = np.array(paste_mask)\n",
    "        paste_image = np.array(paste_image)\n",
    "\n",
    "        mask = add_mask(mask, paste_mask, rb_spot[1], rb_spot[0])\n",
    "\n",
    "        if mask is None:\n",
    "            print(\"mask is None\")\n",
    "            continue\n",
    "\n",
    "        # image add & get condition image\n",
    "        gen_image = add_image(np.array(image).astype(\"uint8\"), paste_image, paste_mask, rb_spot[1], rb_spot[0])\n",
    "\n",
    "        if gen_image is None:\n",
    "            print(\"image is None\")\n",
    "            continue\n",
    "\n",
    "        pre_gen_image = Image.fromarray(np.copy(gen_image).astype(\"uint8\"))\n",
    "        pre_con_image = midas(pre_gen_image, image_resolution=pre_gen_image.height)\n",
    "\n",
    "        gen_image = harmonizer.harmonize(gen_image, mask)\n",
    "        gen_image = Image.fromarray(gen_image.astype(\"uint8\")).convert(\"RGB\")\n",
    "        mask = Image.fromarray(mask.astype(\"uint8\")).convert(\"L\")\n",
    "        con_image = midas(gen_image, image_resolution=gen_image.height)\n",
    "\n",
    "        pre_result_image = pipe(\n",
    "            prompt=prompt.format(\"a person is standing on the road\"),\n",
    "            negative_prompt=negative_prompt,\n",
    "            image=gen_image,\n",
    "            control_image=con_image,\n",
    "            mask_image=mask,\n",
    "            height=gen_image.height,\n",
    "            width=gen_image.width,\n",
    "            num_inference_steps=25,\n",
    "            guidance_scale=7.5,\n",
    "            controlnet_conditioning_scale=0.75,\n",
    "            generator=generator,\n",
    "        ).images[0]\n",
    "\n",
    "        result_image = harmonizer.harmonize(np.array(pre_result_image), np.array(mask))\n",
    "        result_image = Image.fromarray(result_image.astype(\"uint8\")).convert(\"RGB\")\n",
    "\n",
    "        total_result_image = make_result(np.array(result_image), np.array(mask))\n",
    "        total_result_image = Image.fromarray(total_result_image.astype(\"uint8\"))\n",
    "\n",
    "        # save results\n",
    "        image.save(os.path.join(save_origin_image_path, annotation[\"filename\"]))\n",
    "        mask.save(os.path.join(save_mask_path, annotation[\"filename\"]))\n",
    "        pre_gen_image.save(os.path.join(save_paste_image_path, annotation[\"filename\"]))\n",
    "        pre_con_image.save(os.path.join(save_pre_harmo_con_path, annotation[\"filename\"]))\n",
    "        con_image.save(os.path.join(save_after_harmo_con_path, annotation[\"filename\"]))\n",
    "        gen_image.save(os.path.join(save_after_harmo_image_path, annotation[\"filename\"]))\n",
    "        pre_result_image.save(os.path.join(save_result_path, annotation[\"filename\"]))\n",
    "        result_image.save(os.path.join(save_result_harmo_path, annotation[\"filename\"]))\n",
    "        total_result_image.save(os.path.join(save_total_path, annotation[\"filename\"]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Diffusion Inpainting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from diffusers import StableDiffusionInpaintPipeline, DDIMScheduler\n",
    "from controlnet_aux.processor import MidasDetector\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../harmonization\")\n",
    "from harmonization import Harmonization\n",
    "\n",
    "\n",
    "def make_grid(images, rows, cols):\n",
    "    w, h = images[0].size\n",
    "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
    "    for i, image in enumerate(images):\n",
    "        grid.paste(image, box=(i % cols * w, i // cols * h))\n",
    "    return grid\n",
    "\n",
    "\n",
    "def find_outer_contour_coordinates(mask):\n",
    "    # OpenCV의 findContours 함수를 사용하여 이진 이미지의 외곽선을 찾습니다.\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # 외곽선을 이루는 점들의 좌표를 반환합니다.\n",
    "    outer_contour_coords = [[], []]\n",
    "    for contour in contours:\n",
    "        for point in contour:\n",
    "            y, x = point[0]\n",
    "            outer_contour_coords[0].append(y)\n",
    "            outer_contour_coords[1].append(x)\n",
    "\n",
    "    return outer_contour_coords\n",
    "\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    return np.sqrt((point2[0] - point1[0]) ** 2 + (point2[1] - point1[1]) ** 2)\n",
    "\n",
    "\n",
    "def random_coordinate(mask):\n",
    "    # 값이 255인 좌표 찾기\n",
    "    coordinates = find_outer_contour_coordinates(mask)\n",
    "\n",
    "    center_x = int((np.max(coordinates[1]) - np.min(coordinates[1])) / 2) + np.min(coordinates[1])\n",
    "    center_y = int((np.max(coordinates[0]) - np.min(coordinates[0])) / 2) + np.min(coordinates[0])\n",
    "    center = (center_y, center_x)\n",
    "\n",
    "    distances = [euclidean_distance((coord[0], coord[1]), center) for coord in zip(coordinates[0], coordinates[1])]\n",
    "    radius = int(min(distances))\n",
    "\n",
    "    # 랜덤으로 좌표 선택\n",
    "    while True:\n",
    "        random_x = random.randint(center_x - radius, center_x + radius)\n",
    "        random_y = random.randint(center_y - radius, center_y + radius)\n",
    "\n",
    "        try:\n",
    "            if mask[random_y, random_x] != 0:\n",
    "                return (random_y, random_x)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "def add_mask(mask, new_mask, right, bottom):\n",
    "    # 새로운 마스크를 더할 위치 계산\n",
    "    left = right - new_mask.shape[1]\n",
    "    top = bottom - new_mask.shape[0]\n",
    "\n",
    "    # 마스크 영역에 새로운 마스크 더하기\n",
    "    if left < 0 or top < 0:\n",
    "        return None\n",
    "\n",
    "    mask[top:bottom, left:right] += new_mask\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def add_image(image, new_image, mask, right, bottom):\n",
    "    # 새로운 마스크를 더할 위치 계산\n",
    "    left = right - new_image.shape[1]\n",
    "    top = bottom - new_image.shape[0]\n",
    "\n",
    "    # 마스크 영역에 새로운 마스크 더하기\n",
    "    if left < 0 or top < 0:\n",
    "        return None\n",
    "\n",
    "    for h in range(top, bottom):\n",
    "        for w in range(left, right):\n",
    "            if mask[h - top, w - left]:\n",
    "                image[h, w, :] = new_image[h - top, w - left, :]\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def make_dirs(paths):\n",
    "    for path in paths:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def make_result(image, mask):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    image_with_mask_contours = np.copy(image)\n",
    "    cv2.drawContours(image_with_mask_contours, contours, -1, (0, 255, 0), 2)\n",
    "    return image_with_mask_contours\n",
    "\n",
    "\n",
    "device = \"cuda:1\"\n",
    "torch.cuda.set_device(device)\n",
    "\n",
    "# 사전 정의된 Crop 이미지와 마스크\n",
    "mask_path = \"/data/noah/inference/ad_premask/masks\"\n",
    "image_path = \"/data/noah/inference/ad_premask/images\"\n",
    "mask_lists = os.listdir(mask_path)\n",
    "\n",
    "# 생성할 Annotation 정보\n",
    "base_image_path = \"/data/noah/dataset/magna_traffic_light/pre_images\"\n",
    "target_annotation_path = \"/data/noah/dataset/magna_traffic_light/pre_anno\"\n",
    "target_class_name = \"road\"\n",
    "target_height = None\n",
    "\n",
    "save_base_path = \"/data/noah/inference/magna_sd_inpainting\"\n",
    "save_origin_image_path = os.path.join(save_base_path, \"images\")\n",
    "save_mask_path = os.path.join(save_base_path, \"masks\")\n",
    "save_paste_image_path = os.path.join(save_base_path, \"paste_images\")\n",
    "save_after_harmo_image_path = os.path.join(save_base_path, \"after_harmo_images\")\n",
    "save_result_path = os.path.join(save_base_path, \"result_images\")\n",
    "save_result_harmo_path = os.path.join(save_base_path, \"result_harmo_images\")\n",
    "save_total_path = os.path.join(save_base_path, \"total_results\")\n",
    "\n",
    "make_dirs(\n",
    "    [\n",
    "        save_base_path,\n",
    "        save_origin_image_path,\n",
    "        save_mask_path,\n",
    "        save_paste_image_path,\n",
    "        save_after_harmo_image_path,\n",
    "        save_result_path,\n",
    "        save_result_harmo_path,\n",
    "        save_total_path,\n",
    "    ]\n",
    ")\n",
    "\n",
    "midas = MidasDetector.from_pretrained(\"lllyasviel/Annotators\").to(\"cuda:1\")\n",
    "harmonizer = Harmonization(\"/data/noah/ckpt/pretrain_ckpt/duconet/duconet1024.pth\", device=\"cuda:1\")\n",
    "\n",
    "# /data/noah/ckpt/pretrain_ckpt/StableDiffusion/inpaint\n",
    "# /data/noah/ckpt/pretrain_ckpt/StableDiffusion/rv_inpaint\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"/data/noah/ckpt/finetuning/sd_inpaint_coco\", torch_dtype=torch.float16\n",
    ").to(device)\n",
    "\n",
    "\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "generator = torch.Generator(device=device).manual_seed(42)\n",
    "\n",
    "prompt = \"{}, best quality, extremely detailed, clearness, naturalness, film grain, crystal clear, photo with color, actuality\"\n",
    "negative_prompt = \"cartoon, anime, painting, disfigured, immature, blur, picture, 3D, render, semi-realistic, drawing, poorly drawn, bad anatomy, wrong anatomy, gray scale, worst quality, low quality, sketch, text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck\"\n",
    "\n",
    "\n",
    "for ann_idx, ann_name in tqdm(enumerate(os.listdir(target_annotation_path)[:40])):\n",
    "    annotation_path = os.path.join(target_annotation_path, ann_name)\n",
    "\n",
    "    with open(annotation_path, \"r\") as f:\n",
    "        annotation = json.load(f)\n",
    "\n",
    "    target_indexs = []\n",
    "\n",
    "    for idx, ann in enumerate(annotation[\"annotations\"]):\n",
    "        if ann[\"label\"] == target_class_name:\n",
    "            target_indexs.append(idx)\n",
    "            break\n",
    "\n",
    "    if not len(target_indexs):\n",
    "        continue\n",
    "\n",
    "    iter_cnt = 0\n",
    "\n",
    "    while True:\n",
    "        # polygon to mask\n",
    "        if iter_cnt > 50:\n",
    "            break\n",
    "        else:\n",
    "            iter_cnt += 1\n",
    "        target_index = random.choice(target_indexs)\n",
    "        mask = np.zeros((annotation[\"metadata\"][\"height\"], annotation[\"metadata\"][\"width\"]))\n",
    "        image = Image.open(os.path.join(base_image_path, annotation[\"parent_path\"][1:], annotation[\"filename\"]))\n",
    "        target_mask = np.copy(mask)\n",
    "\n",
    "        point = np.array(annotation[\"annotations\"][target_index][\"points\"], dtype=np.int32)\n",
    "        try:\n",
    "            target_mask = cv2.fillPoly(target_mask, [point], color=255).astype(np.uint8)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        rb_spot = random_coordinate(target_mask)  # height, width 순\n",
    "\n",
    "        # rb_spot x값을 기준으로 height 선정 및 target_height 산출\n",
    "        target_height = random.randint(350, 600)\n",
    "\n",
    "        # 사전에 저장한 mask로부터 랜덤으로 하나 선택 후 target_height로 리사이징\n",
    "        # mask_name = random.choice(mask_lists)\n",
    "        mask_name = mask_lists[ann_idx]\n",
    "\n",
    "        image_pth = os.path.join(image_path, mask_name)\n",
    "        mask_pth = os.path.join(mask_path, mask_name)\n",
    "\n",
    "        paste_image = Image.open(image_pth)\n",
    "        paste_mask = Image.open(mask_pth)\n",
    "\n",
    "        ratio = float(target_height) / paste_mask.height\n",
    "        paste_mask = paste_mask.resize((int(paste_mask.width * ratio), int(paste_mask.height * ratio)))\n",
    "        paste_image = paste_image.resize((int(paste_image.width * ratio), int(paste_image.height * ratio)))\n",
    "\n",
    "        paste_mask = np.array(paste_mask)\n",
    "        paste_image = np.array(paste_image)\n",
    "\n",
    "        mask = add_mask(mask, paste_mask, rb_spot[1], rb_spot[0])\n",
    "\n",
    "        if mask is None:\n",
    "            print(\"mask is None\")\n",
    "            continue\n",
    "\n",
    "        # image add & get condition image\n",
    "        gen_image = add_image(np.array(image).astype(\"uint8\"), paste_image, paste_mask, rb_spot[1], rb_spot[0])\n",
    "\n",
    "        if gen_image is None:\n",
    "            print(\"image is None\")\n",
    "            continue\n",
    "\n",
    "        pre_gen_image = Image.fromarray(np.copy(gen_image).astype(\"uint8\"))\n",
    "\n",
    "        gen_image = harmonizer.harmonize(gen_image, mask)\n",
    "        gen_image = Image.fromarray(gen_image.astype(\"uint8\")).convert(\"RGB\")\n",
    "        mask = Image.fromarray(mask.astype(\"uint8\")).convert(\"L\")\n",
    "\n",
    "        pre_result_image = pipe(\n",
    "            prompt=prompt.format(\"a person is standing on the road\"),\n",
    "            negative_prompt=negative_prompt,\n",
    "            image=gen_image,\n",
    "            mask_image=mask,\n",
    "            height=gen_image.height,\n",
    "            width=gen_image.width,\n",
    "            num_inference_steps=25,\n",
    "            guidance_scale=7.5,\n",
    "            generator=generator,\n",
    "        ).images[0]\n",
    "\n",
    "        result_image = harmonizer.harmonize(np.array(pre_result_image), np.array(mask))\n",
    "        result_image = Image.fromarray(result_image.astype(\"uint8\")).convert(\"RGB\")\n",
    "\n",
    "        total_result_image = make_result(np.array(result_image), np.array(mask))\n",
    "        total_result_image = Image.fromarray(total_result_image.astype(\"uint8\"))\n",
    "\n",
    "        # save results\n",
    "        image.save(os.path.join(save_origin_image_path, annotation[\"filename\"]))\n",
    "        mask.save(os.path.join(save_mask_path, annotation[\"filename\"]))\n",
    "        pre_gen_image.save(os.path.join(save_paste_image_path, annotation[\"filename\"]))\n",
    "        gen_image.save(os.path.join(save_after_harmo_image_path, annotation[\"filename\"]))\n",
    "        pre_result_image.save(os.path.join(save_result_path, annotation[\"filename\"]))\n",
    "        result_image.save(os.path.join(save_result_harmo_path, annotation[\"filename\"]))\n",
    "        total_result_image.save(os.path.join(save_total_path, annotation[\"filename\"]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from diffusers import StableDiffusionInpaintPipeline, DDIMScheduler\n",
    "from controlnet_aux.processor import MidasDetector\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../harmonization\")\n",
    "from harmonization import Harmonization\n",
    "\n",
    "\n",
    "def make_grid(images, rows, cols):\n",
    "    w, h = images[0].size\n",
    "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
    "    for i, image in enumerate(images):\n",
    "        grid.paste(image, box=(i % cols * w, i // cols * h))\n",
    "    return grid\n",
    "\n",
    "\n",
    "def find_outer_contour_coordinates(mask):\n",
    "    # OpenCV의 findContours 함수를 사용하여 이진 이미지의 외곽선을 찾습니다.\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # 외곽선을 이루는 점들의 좌표를 반환합니다.\n",
    "    outer_contour_coords = [[], []]\n",
    "    for contour in contours:\n",
    "        for point in contour:\n",
    "            y, x = point[0]\n",
    "            outer_contour_coords[0].append(y)\n",
    "            outer_contour_coords[1].append(x)\n",
    "\n",
    "    return outer_contour_coords\n",
    "\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    return np.sqrt((point2[0] - point1[0]) ** 2 + (point2[1] - point1[1]) ** 2)\n",
    "\n",
    "\n",
    "def random_coordinate(mask):\n",
    "    # 값이 255인 좌표 찾기\n",
    "    coordinates = find_outer_contour_coordinates(mask)\n",
    "\n",
    "    center_x = int((np.max(coordinates[1]) - np.min(coordinates[1])) / 2) + np.min(coordinates[1])\n",
    "    center_y = int((np.max(coordinates[0]) - np.min(coordinates[0])) / 2) + np.min(coordinates[0])\n",
    "    center = (center_y, center_x)\n",
    "\n",
    "    distances = [euclidean_distance((coord[0], coord[1]), center) for coord in zip(coordinates[0], coordinates[1])]\n",
    "    radius = int(min(distances))\n",
    "\n",
    "    # 랜덤으로 좌표 선택\n",
    "    while True:\n",
    "        random_x = random.randint(center_x - radius, center_x + radius)\n",
    "        random_y = random.randint(center_y - radius, center_y + radius)\n",
    "\n",
    "        try:\n",
    "            if mask[random_y, random_x] != 0:\n",
    "                return (random_y, random_x)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "def add_mask(mask, new_mask, right, bottom):\n",
    "    # 새로운 마스크를 더할 위치 계산\n",
    "    left = right - new_mask.shape[1]\n",
    "    top = bottom - new_mask.shape[0]\n",
    "\n",
    "    # 마스크 영역에 새로운 마스크 더하기\n",
    "    if left < 0 or top < 0:\n",
    "        return None\n",
    "\n",
    "    mask[top:bottom, left:right] += new_mask\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def add_image(image, new_image, mask, right, bottom):\n",
    "    # 새로운 마스크를 더할 위치 계산\n",
    "    left = right - new_image.shape[1]\n",
    "    top = bottom - new_image.shape[0]\n",
    "\n",
    "    # 마스크 영역에 새로운 마스크 더하기\n",
    "    if left < 0 or top < 0:\n",
    "        return None\n",
    "\n",
    "    for h in range(top, bottom):\n",
    "        for w in range(left, right):\n",
    "            if mask[h - top, w - left]:\n",
    "                image[h, w, :] = new_image[h - top, w - left, :]\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def make_dirs(paths):\n",
    "    for path in paths:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def make_result(image, mask):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    image_with_mask_contours = np.copy(image)\n",
    "    cv2.drawContours(image_with_mask_contours, contours, -1, (0, 255, 0), 2)\n",
    "    return image_with_mask_contours\n",
    "\n",
    "\n",
    "device = \"cuda:1\"\n",
    "torch.cuda.set_device(device)\n",
    "\n",
    "# 사전 정의된 Crop 이미지와 마스크\n",
    "mask_path = \"/data/noah/inference/ad_premask/masks\"\n",
    "image_path = \"/data/noah/inference/ad_premask/images\"\n",
    "mask_lists = os.listdir(mask_path)\n",
    "\n",
    "# 생성할 Annotation 정보\n",
    "base_image_path = \"/data/noah/dataset/magna_traffic_light/pre_images\"\n",
    "target_annotation_path = \"/data/noah/dataset/magna_traffic_light/pre_anno\"\n",
    "target_class_name = \"road\"\n",
    "target_height = None\n",
    "\n",
    "save_base_path = \"/data/noah/inference/magna_sd_inpainting_pre\"\n",
    "save_origin_image_path = os.path.join(save_base_path, \"images\")\n",
    "save_mask_path = os.path.join(save_base_path, \"masks\")\n",
    "save_paste_image_path = os.path.join(save_base_path, \"paste_images\")\n",
    "save_after_harmo_image_path = os.path.join(save_base_path, \"after_harmo_images\")\n",
    "save_result_path = os.path.join(save_base_path, \"result_images\")\n",
    "save_result_harmo_path = os.path.join(save_base_path, \"result_harmo_images\")\n",
    "save_total_path = os.path.join(save_base_path, \"total_results\")\n",
    "\n",
    "make_dirs(\n",
    "    [\n",
    "        save_base_path,\n",
    "        save_origin_image_path,\n",
    "        save_mask_path,\n",
    "        save_paste_image_path,\n",
    "        save_after_harmo_image_path,\n",
    "        save_result_path,\n",
    "        save_result_harmo_path,\n",
    "        save_total_path,\n",
    "    ]\n",
    ")\n",
    "\n",
    "midas = MidasDetector.from_pretrained(\"lllyasviel/Annotators\").to(\"cuda:1\")\n",
    "harmonizer = Harmonization(\"/data/noah/ckpt/pretrain_ckpt/duconet/duconet1024.pth\", device=\"cuda:1\")\n",
    "\n",
    "# /data/noah/ckpt/pretrain_ckpt/StableDiffusion/inpaint\n",
    "# /data/noah/ckpt/pretrain_ckpt/StableDiffusion/rv_inpaint\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"/data/noah/ckpt/pretrain_ckpt/StableDiffusion/inpaint\", torch_dtype=torch.float16\n",
    ").to(device)\n",
    "\n",
    "\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "generator = torch.Generator(device=device).manual_seed(42)\n",
    "\n",
    "prompt = \"{}, best quality, extremely detailed, clearness, naturalness, film grain, crystal clear, photo with color, actuality\"\n",
    "negative_prompt = \"cartoon, anime, painting, disfigured, immature, blur, picture, 3D, render, semi-realistic, drawing, poorly drawn, bad anatomy, wrong anatomy, gray scale, worst quality, low quality, sketch, text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck\"\n",
    "\n",
    "\n",
    "for ann_idx, ann_name in tqdm(enumerate(os.listdir(target_annotation_path)[:40])):\n",
    "    annotation_path = os.path.join(target_annotation_path, ann_name)\n",
    "\n",
    "    with open(annotation_path, \"r\") as f:\n",
    "        annotation = json.load(f)\n",
    "\n",
    "    target_indexs = []\n",
    "\n",
    "    for idx, ann in enumerate(annotation[\"annotations\"]):\n",
    "        if ann[\"label\"] == target_class_name:\n",
    "            target_indexs.append(idx)\n",
    "            break\n",
    "\n",
    "    if not len(target_indexs):\n",
    "        continue\n",
    "\n",
    "    iter_cnt = 0\n",
    "\n",
    "    while True:\n",
    "        # polygon to mask\n",
    "        if iter_cnt > 50:\n",
    "            break\n",
    "        else:\n",
    "            iter_cnt += 1\n",
    "\n",
    "        target_index = random.choice(target_indexs)\n",
    "        mask = np.zeros((annotation[\"metadata\"][\"height\"], annotation[\"metadata\"][\"width\"]))\n",
    "        image = Image.open(os.path.join(base_image_path, annotation[\"parent_path\"][1:], annotation[\"filename\"]))\n",
    "        target_mask = np.copy(mask)\n",
    "\n",
    "        point = np.array(annotation[\"annotations\"][target_index][\"points\"], dtype=np.int32)\n",
    "        try:\n",
    "            target_mask = cv2.fillPoly(target_mask, [point], color=255).astype(np.uint8)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        rb_spot = random_coordinate(target_mask)  # height, width 순\n",
    "\n",
    "        # rb_spot x값을 기준으로 height 선정 및 target_height 산출\n",
    "        target_height = random.randint(350, 600)\n",
    "\n",
    "        # 사전에 저장한 mask로부터 랜덤으로 하나 선택 후 target_height로 리사이징\n",
    "        # mask_name = random.choice(mask_lists)\n",
    "        mask_name = mask_lists[ann_idx]\n",
    "\n",
    "        image_pth = os.path.join(image_path, mask_name)\n",
    "        mask_pth = os.path.join(mask_path, mask_name)\n",
    "\n",
    "        paste_image = Image.open(image_pth)\n",
    "        paste_mask = Image.open(mask_pth)\n",
    "\n",
    "        ratio = float(target_height) / paste_mask.height\n",
    "        paste_mask = paste_mask.resize((int(paste_mask.width * ratio), int(paste_mask.height * ratio)))\n",
    "        paste_image = paste_image.resize((int(paste_image.width * ratio), int(paste_image.height * ratio)))\n",
    "\n",
    "        paste_mask = np.array(paste_mask)\n",
    "        paste_image = np.array(paste_image)\n",
    "\n",
    "        mask = add_mask(mask, paste_mask, rb_spot[1], rb_spot[0])\n",
    "\n",
    "        if mask is None:\n",
    "            print(\"mask is None\")\n",
    "            continue\n",
    "\n",
    "        # image add & get condition image\n",
    "        gen_image = add_image(np.array(image).astype(\"uint8\"), paste_image, paste_mask, rb_spot[1], rb_spot[0])\n",
    "\n",
    "        if gen_image is None:\n",
    "            print(\"image is None\")\n",
    "            continue\n",
    "\n",
    "        pre_gen_image = Image.fromarray(np.copy(gen_image).astype(\"uint8\"))\n",
    "\n",
    "        gen_image = harmonizer.harmonize(gen_image, mask)\n",
    "        gen_image = Image.fromarray(gen_image.astype(\"uint8\")).convert(\"RGB\")\n",
    "        mask = Image.fromarray(mask.astype(\"uint8\")).convert(\"L\")\n",
    "\n",
    "        pre_result_image = pipe(\n",
    "            prompt=prompt.format(\"a person is standing on the road\"),\n",
    "            negative_prompt=negative_prompt,\n",
    "            image=gen_image,\n",
    "            mask_image=mask,\n",
    "            height=gen_image.height,\n",
    "            width=gen_image.width,\n",
    "            num_inference_steps=25,\n",
    "            guidance_scale=7.5,\n",
    "            generator=generator,\n",
    "        ).images[0]\n",
    "\n",
    "        result_image = harmonizer.harmonize(np.array(pre_result_image), np.array(mask))\n",
    "        result_image = Image.fromarray(result_image.astype(\"uint8\")).convert(\"RGB\")\n",
    "\n",
    "        total_result_image = make_result(np.array(result_image), np.array(mask))\n",
    "        total_result_image = Image.fromarray(total_result_image.astype(\"uint8\"))\n",
    "\n",
    "        # save results\n",
    "        image.save(os.path.join(save_origin_image_path, annotation[\"filename\"]))\n",
    "        mask.save(os.path.join(save_mask_path, annotation[\"filename\"]))\n",
    "        pre_gen_image.save(os.path.join(save_paste_image_path, annotation[\"filename\"]))\n",
    "        gen_image.save(os.path.join(save_after_harmo_image_path, annotation[\"filename\"]))\n",
    "        pre_result_image.save(os.path.join(save_result_path, annotation[\"filename\"]))\n",
    "        result_image.save(os.path.join(save_result_harmo_path, annotation[\"filename\"]))\n",
    "        total_result_image.save(os.path.join(save_total_path, annotation[\"filename\"]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from diffusers import StableDiffusionInpaintPipeline, DDIMScheduler\n",
    "from controlnet_aux.processor import MidasDetector\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../harmonization\")\n",
    "from harmonization import Harmonization\n",
    "\n",
    "\n",
    "def make_grid(images, rows, cols):\n",
    "    w, h = images[0].size\n",
    "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
    "    for i, image in enumerate(images):\n",
    "        grid.paste(image, box=(i % cols * w, i // cols * h))\n",
    "    return grid\n",
    "\n",
    "\n",
    "def find_outer_contour_coordinates(mask):\n",
    "    # OpenCV의 findContours 함수를 사용하여 이진 이미지의 외곽선을 찾습니다.\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # 외곽선을 이루는 점들의 좌표를 반환합니다.\n",
    "    outer_contour_coords = [[], []]\n",
    "    for contour in contours:\n",
    "        for point in contour:\n",
    "            y, x = point[0]\n",
    "            outer_contour_coords[0].append(y)\n",
    "            outer_contour_coords[1].append(x)\n",
    "\n",
    "    return outer_contour_coords\n",
    "\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    return np.sqrt((point2[0] - point1[0]) ** 2 + (point2[1] - point1[1]) ** 2)\n",
    "\n",
    "\n",
    "def random_coordinate(mask):\n",
    "    # 값이 255인 좌표 찾기\n",
    "    coordinates = find_outer_contour_coordinates(mask)\n",
    "\n",
    "    center_x = int((np.max(coordinates[1]) - np.min(coordinates[1])) / 2) + np.min(coordinates[1])\n",
    "    center_y = int((np.max(coordinates[0]) - np.min(coordinates[0])) / 2) + np.min(coordinates[0])\n",
    "    center = (center_y, center_x)\n",
    "\n",
    "    distances = [euclidean_distance((coord[0], coord[1]), center) for coord in zip(coordinates[0], coordinates[1])]\n",
    "    radius = int(min(distances))\n",
    "\n",
    "    # 랜덤으로 좌표 선택\n",
    "    while True:\n",
    "        random_x = random.randint(center_x - radius, center_x + radius)\n",
    "        random_y = random.randint(center_y - radius, center_y + radius)\n",
    "\n",
    "        try:\n",
    "            if mask[random_y, random_x] != 0:\n",
    "                return (random_y, random_x)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "def add_mask(mask, new_mask, right, bottom):\n",
    "    # 새로운 마스크를 더할 위치 계산\n",
    "    left = right - new_mask.shape[1]\n",
    "    top = bottom - new_mask.shape[0]\n",
    "\n",
    "    # 마스크 영역에 새로운 마스크 더하기\n",
    "    if left < 0 or top < 0:\n",
    "        return None\n",
    "\n",
    "    mask[top:bottom, left:right] += new_mask\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def add_image(image, new_image, mask, right, bottom):\n",
    "    # 새로운 마스크를 더할 위치 계산\n",
    "    left = right - new_image.shape[1]\n",
    "    top = bottom - new_image.shape[0]\n",
    "\n",
    "    # 마스크 영역에 새로운 마스크 더하기\n",
    "    if left < 0 or top < 0:\n",
    "        return None\n",
    "\n",
    "    for h in range(top, bottom):\n",
    "        for w in range(left, right):\n",
    "            if mask[h - top, w - left]:\n",
    "                image[h, w, :] = new_image[h - top, w - left, :]\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def make_dirs(paths):\n",
    "    for path in paths:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def make_result(image, mask):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    image_with_mask_contours = np.copy(image)\n",
    "    cv2.drawContours(image_with_mask_contours, contours, -1, (0, 255, 0), 2)\n",
    "    return image_with_mask_contours\n",
    "\n",
    "\n",
    "device = \"cuda:1\"\n",
    "torch.cuda.set_device(device)\n",
    "\n",
    "# 사전 정의된 Crop 이미지와 마스크\n",
    "mask_path = \"/data/noah/inference/ad_premask/masks\"\n",
    "image_path = \"/data/noah/inference/ad_premask/images\"\n",
    "mask_lists = os.listdir(mask_path)\n",
    "\n",
    "# 생성할 Annotation 정보\n",
    "base_image_path = \"/data/noah/dataset/magna_traffic_light/pre_images\"\n",
    "target_annotation_path = \"/data/noah/dataset/magna_traffic_light/pre_anno\"\n",
    "target_class_name = \"road\"\n",
    "target_height = None\n",
    "\n",
    "save_base_path = \"/data/noah/inference/magna_rv_inpainting_pre\"\n",
    "save_origin_image_path = os.path.join(save_base_path, \"images\")\n",
    "save_mask_path = os.path.join(save_base_path, \"masks\")\n",
    "save_paste_image_path = os.path.join(save_base_path, \"paste_images\")\n",
    "save_after_harmo_image_path = os.path.join(save_base_path, \"after_harmo_images\")\n",
    "save_result_path = os.path.join(save_base_path, \"result_images\")\n",
    "save_result_harmo_path = os.path.join(save_base_path, \"result_harmo_images\")\n",
    "save_total_path = os.path.join(save_base_path, \"total_results\")\n",
    "\n",
    "make_dirs(\n",
    "    [\n",
    "        save_base_path,\n",
    "        save_origin_image_path,\n",
    "        save_mask_path,\n",
    "        save_paste_image_path,\n",
    "        save_after_harmo_image_path,\n",
    "        save_result_path,\n",
    "        save_result_harmo_path,\n",
    "        save_total_path,\n",
    "    ]\n",
    ")\n",
    "\n",
    "midas = MidasDetector.from_pretrained(\"lllyasviel/Annotators\").to(\"cuda:1\")\n",
    "harmonizer = Harmonization(\"/data/noah/ckpt/pretrain_ckpt/duconet/duconet1024.pth\", device=\"cuda:1\")\n",
    "\n",
    "# /data/noah/ckpt/pretrain_ckpt/StableDiffusion/inpaint\n",
    "# /data/noah/ckpt/pretrain_ckpt/StableDiffusion/rv_inpaint\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"/data/noah/ckpt/pretrain_ckpt/StableDiffusion/rv_inpaint\", torch_dtype=torch.float16\n",
    ").to(device)\n",
    "\n",
    "\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "generator = torch.Generator(device=device).manual_seed(42)\n",
    "\n",
    "prompt = \"{}, best quality, extremely detailed, clearness, naturalness, film grain, crystal clear, photo with color, actuality\"\n",
    "negative_prompt = \"cartoon, anime, painting, disfigured, immature, blur, picture, 3D, render, semi-realistic, drawing, poorly drawn, bad anatomy, wrong anatomy, gray scale, worst quality, low quality, sketch, text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck\"\n",
    "\n",
    "\n",
    "for ann_idx, ann_name in tqdm(enumerate(os.listdir(target_annotation_path)[:40])):\n",
    "    annotation_path = os.path.join(target_annotation_path, ann_name)\n",
    "\n",
    "    with open(annotation_path, \"r\") as f:\n",
    "        annotation = json.load(f)\n",
    "\n",
    "    target_indexs = []\n",
    "\n",
    "    for idx, ann in enumerate(annotation[\"annotations\"]):\n",
    "        if ann[\"label\"] == target_class_name:\n",
    "            target_indexs.append(idx)\n",
    "            break\n",
    "\n",
    "    if not len(target_indexs):\n",
    "        continue\n",
    "\n",
    "    iter_cnt = 0\n",
    "\n",
    "    while True:\n",
    "        # polygon to mask\n",
    "        if iter_cnt > 50:\n",
    "            break\n",
    "        else:\n",
    "            iter_cnt += 1\n",
    "        target_index = random.choice(target_indexs)\n",
    "        mask = np.zeros((annotation[\"metadata\"][\"height\"], annotation[\"metadata\"][\"width\"]))\n",
    "        image = Image.open(os.path.join(base_image_path, annotation[\"parent_path\"][1:], annotation[\"filename\"]))\n",
    "        target_mask = np.copy(mask)\n",
    "\n",
    "        point = np.array(annotation[\"annotations\"][target_index][\"points\"], dtype=np.int32)\n",
    "        try:\n",
    "            target_mask = cv2.fillPoly(target_mask, [point], color=255).astype(np.uint8)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        rb_spot = random_coordinate(target_mask)  # height, width 순\n",
    "\n",
    "        # rb_spot x값을 기준으로 height 선정 및 target_height 산출\n",
    "        target_height = random.randint(350, 600)\n",
    "\n",
    "        # 사전에 저장한 mask로부터 랜덤으로 하나 선택 후 target_height로 리사이징\n",
    "        # mask_name = random.choice(mask_lists)\n",
    "        mask_name = mask_lists[ann_idx]\n",
    "\n",
    "        image_pth = os.path.join(image_path, mask_name)\n",
    "        mask_pth = os.path.join(mask_path, mask_name)\n",
    "\n",
    "        paste_image = Image.open(image_pth)\n",
    "        paste_mask = Image.open(mask_pth)\n",
    "\n",
    "        ratio = float(target_height) / paste_mask.height\n",
    "        paste_mask = paste_mask.resize((int(paste_mask.width * ratio), int(paste_mask.height * ratio)))\n",
    "        paste_image = paste_image.resize((int(paste_image.width * ratio), int(paste_image.height * ratio)))\n",
    "\n",
    "        paste_mask = np.array(paste_mask)\n",
    "        paste_image = np.array(paste_image)\n",
    "\n",
    "        mask = add_mask(mask, paste_mask, rb_spot[1], rb_spot[0])\n",
    "\n",
    "        if mask is None:\n",
    "            print(\"mask is None\")\n",
    "            continue\n",
    "\n",
    "        # image add & get condition image\n",
    "        gen_image = add_image(np.array(image).astype(\"uint8\"), paste_image, paste_mask, rb_spot[1], rb_spot[0])\n",
    "\n",
    "        if gen_image is None:\n",
    "            print(\"image is None\")\n",
    "            continue\n",
    "\n",
    "        pre_gen_image = Image.fromarray(np.copy(gen_image).astype(\"uint8\"))\n",
    "\n",
    "        gen_image = harmonizer.harmonize(gen_image, mask)\n",
    "        gen_image = Image.fromarray(gen_image.astype(\"uint8\")).convert(\"RGB\")\n",
    "        mask = Image.fromarray(mask.astype(\"uint8\")).convert(\"L\")\n",
    "\n",
    "        pre_result_image = pipe(\n",
    "            prompt=prompt.format(\"a person is standing on the road\"),\n",
    "            negative_prompt=negative_prompt,\n",
    "            image=gen_image,\n",
    "            mask_image=mask,\n",
    "            height=gen_image.height,\n",
    "            width=gen_image.width,\n",
    "            num_inference_steps=25,\n",
    "            guidance_scale=7.5,\n",
    "            generator=generator,\n",
    "        ).images[0]\n",
    "\n",
    "        result_image = harmonizer.harmonize(np.array(pre_result_image), np.array(mask))\n",
    "        result_image = Image.fromarray(result_image.astype(\"uint8\")).convert(\"RGB\")\n",
    "\n",
    "        total_result_image = make_result(np.array(result_image), np.array(mask))\n",
    "        total_result_image = Image.fromarray(total_result_image.astype(\"uint8\"))\n",
    "\n",
    "        # save results\n",
    "        image.save(os.path.join(save_origin_image_path, annotation[\"filename\"]))\n",
    "        mask.save(os.path.join(save_mask_path, annotation[\"filename\"]))\n",
    "        pre_gen_image.save(os.path.join(save_paste_image_path, annotation[\"filename\"]))\n",
    "        gen_image.save(os.path.join(save_after_harmo_image_path, annotation[\"filename\"]))\n",
    "        pre_result_image.save(os.path.join(save_result_path, annotation[\"filename\"]))\n",
    "        result_image.save(os.path.join(save_result_harmo_path, annotation[\"filename\"]))\n",
    "        total_result_image.save(os.path.join(save_total_path, annotation[\"filename\"]))\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
